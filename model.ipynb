{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c589301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import stat\n",
    "import math\n",
    "import random\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d12cb-8d4c-4fea-90be-697c165441f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b48ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b4fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    try:\n",
    "        from keras import backend as K\n",
    "    except:\n",
    "        from tensorflow.keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        if layer_type == 'Model':\n",
    "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "        single_layer_mem = 1\n",
    "        out_shape = l.output_shape\n",
    "        if type(out_shape) is list:\n",
    "            out_shape = out_shape[0]\n",
    "        for s in out_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "        number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "        number_size = 8.0\n",
    "\n",
    "    total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_memory_usage(BATCH_SIZE, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d853f0a",
   "metadata": {},
   "source": [
    "## !Extracting data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_ZIP = './Data/data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(LOCAL_ZIP, 'r')\n",
    "\n",
    "tqdm(zip_ref.extractall('./Data/'))\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4b37e",
   "metadata": {},
   "source": [
    "## Code Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be251aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_DIR = './Data/Clean/'\n",
    "DIRTY_DIR = './Data/Dirty/'\n",
    "TRAINING_DIR = './Data/Training/'\n",
    "TESTING_DIR = './Data/Testing/'\n",
    "DEV_DIR = './Data/Dev/'\n",
    "\n",
    "SPLIT_DIST = 0.1\n",
    "\n",
    "batik_classes = os.listdir(CLEAN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00bdd7d",
   "metadata": {},
   "source": [
    "## Changing file permission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c215b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def change_perm(target):\n",
    "    for batik_class in batik_classes:\n",
    "        dir = os.path.join(target, batik_class)\n",
    "        dir_content = os.listdir(dir)\n",
    "\n",
    "        for image in tqdm(dir_content, ascii = False, desc = batik_class):\n",
    "            dst_dir = os.path.join(dir, image)\n",
    "            os.chmod(dst_dir, stat.S_IRWXU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fecb5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change_perm(CLEAN_DIR)\n",
    "change_perm(DIRTY_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7311f",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "# !RUN WITH CAUTION!\n",
    "## Data Splitting\n",
    " Making the DIR necessary for storing images and spreading it from CLEAN_DIR to apropriate dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df15446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_image(target):\n",
    "    for batik_class in batik_classes:\n",
    "        dir = os.path.join(target, batik_class)\n",
    "        dir_content = os.listdir(dir)\n",
    "\n",
    "        # Calculating how much image for splitting\n",
    "        split_dist = math.ceil(len(dir_content) * SPLIT_DIST)\n",
    "\n",
    "        # Picking random images\n",
    "        testing_images = random.choices(dir_content, k = split_dist)\n",
    "\n",
    "        # Moving things around\n",
    "        for image in tqdm(dir_content, desc = batik_class):\n",
    "            # If image is picked for testing\n",
    "            if image in testing_images:\n",
    "                src_dir = os.path.join(dir, image)\n",
    "                dst_dir = os.path.join(TESTING_DIR, batik_class)\n",
    "\n",
    "                shutil.copy(src_dir, dst_dir)\n",
    "            else:\n",
    "                src_dir = os.path.join(dir, image)\n",
    "                dst_dir = os.path.join(TRAINING_DIR, batik_class)\n",
    "\n",
    "                shutil.copy(src_dir, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351753a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MKDIR data subdir\n",
    "try:\n",
    "    os.mkdir(TRAINING_DIR)\n",
    "    os.mkdir(TESTING_DIR)\n",
    "    os.mkdir(DEV_DIR)\n",
    "except:\n",
    "    print('Data subdir folder already exist')\n",
    "\n",
    "# MKDIR working subdir\n",
    "for batik_class in batik_classes:\n",
    "    try:\n",
    "        dir = os.path.join(TRAINING_DIR, batik_class)\n",
    "        os.mkdir(dir)\n",
    "\n",
    "        dir = os.path.join(TESTING_DIR, batik_class)\n",
    "        os.mkdir(dir)\n",
    "\n",
    "        dir = os.path.join(DEV_DIR, batik_class)\n",
    "        os.mkdir(dir)\n",
    "    except:\n",
    "        print('Working subdir folder already exist')\n",
    "        break\n",
    "\n",
    "move_image(CLEAN_DIR)\n",
    "move_image(DIRTY_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e84706",
   "metadata": {},
   "source": [
    "## Purge images from working dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be205124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge_working_image(target):\n",
    "    for batik_class in tqdm(batik_classes, desc = target):\n",
    "        dir = os.path.join(target, batik_class)\n",
    "        \n",
    "        #print('Deleting ' + dir)\n",
    "        shutil.rmtree(dir, ignore_errors = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "purge_working_image(TRAINING_DIR)\n",
    "purge_working_image(TESTING_DIR)\n",
    "purge_working_image(DEV_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4816a",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5445a1",
   "metadata": {},
   "source": [
    "## Counting total images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_batik(target):\n",
    "    try:\n",
    "        batik_counter = {}\n",
    "\n",
    "        for batik_class in batik_classes:\n",
    "            dir = os.path.join(target, batik_class)\n",
    "            dir_content = os.listdir(dir)\n",
    "\n",
    "            batik_counter[batik_class] = 0\n",
    "            for image in dir_content:\n",
    "                batik_counter[batik_class] += 1\n",
    "    except:\n",
    "        print('Directory Empty!')\n",
    "        print()\n",
    "    else:\n",
    "        for i in batik_counter:\n",
    "            print(i + ' = ' + str(batik_counter[i]))\n",
    "\n",
    "        print()\n",
    "        print('Total images: ' + str(sum(batik_counter.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61895bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CLEAN IMAGES')\n",
    "print('-------------------------------------')\n",
    "\n",
    "count_batik(CLEAN_DIR)\n",
    "\n",
    "print('DIRTY IMAGES')\n",
    "print('-------------------------------------')\n",
    "\n",
    "count_batik(DIRTY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d509234",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAINING IMAGES')\n",
    "print('-------------------------------------')\n",
    "\n",
    "count_batik(TRAINING_DIR)\n",
    "\n",
    "print('TESTING IMAGES')\n",
    "print('-------------------------------------')\n",
    "\n",
    "count_batik(TESTING_DIR)\n",
    "\n",
    "print('DEV IMAGES')\n",
    "print('-------------------------------------')\n",
    "\n",
    "count_batik(DEV_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe3c17",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa82ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [150, 150]\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1839bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datagen = ImageDataGenerator(\n",
    "    # Might need further augmentation\n",
    "    rescale = 1/255.0,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "testing_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255.0,\n",
    ")\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "testing_generator = testing_datagen.flow_from_directory(\n",
    "    TESTING_DIR,\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e11036",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b738fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetV3_model = tf.keras.applications.MobileNetV3Large(\n",
    "    include_top=False,\n",
    "    input_shape=IMAGE_SHAPE + [3]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48665f8a",
   "metadata": {},
   "source": [
    "efn_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    input_shape=IMAGE_SHAPE + [3]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c14aa5c",
   "metadata": {},
   "source": [
    "nasnetmobile_model = tf.keras.applications.NASNetMobile(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_shape=IMAGE_SHAPE + [3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d520725",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenetV3_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566c778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mobilenetV3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "output_layer = tf.keras.layers.Dense(20, activation='softmax')\n",
    "model = tf.keras.Sequential([\n",
    "    mobilenetV3_model,\n",
    "    global_average_layer,\n",
    "    output_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ef502",
   "metadata": {},
   "source": [
    "#Vanilla model\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(IMAGE_SHAPE + [3])),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    #20 Batik class, might add more later?\n",
    "    tf.keras.layers.Dense(20, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8613bb",
   "metadata": {},
   "source": [
    "## Compiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fedfb5",
   "metadata": {},
   "source": [
    "Using time-based decay learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34633be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 550\n",
    "\n",
    "decay = LEARNING_RATE / EPOCHS\n",
    "\n",
    "ACCURACY_THRESHOLD = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dab8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') > ACCURACY_THRESHOLD):   \n",
    "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))\n",
    "            self.model.stop_training = True\n",
    "\n",
    "CHECKPOINT_DIR = 'Checkpoint/'\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    CHECKPOINT_DIR,\n",
    "    monitor='accuracy',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_freq=BATCH_SIZE*5\n",
    ")\n",
    "\n",
    "def lr_time_based_decay(epoch, lr):\n",
    "    result = lr * 1 / (1 + decay * epoch)\n",
    "    print('lr = ' + str(result))\n",
    "    return result\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lr_time_based_decay\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=10,\n",
    "    min_delta=0.001, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ecb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cbf94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0704546d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data=testing_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[callback, checkpoint, lr_scheduler, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659226e",
   "metadata": {},
   "source": [
    "## Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3651d-f2fc-40d3-8493-e14f8b0fe924",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(epochs, acc, 'b', label='Training accuracy')\n",
    "axs[0].plot(epochs, val_acc, 'y', label='Validation accuracy')\n",
    "axs[0].legend(loc=0)\n",
    "\n",
    "axs[1].plot(epochs, loss, 'b', label='Training loss')\n",
    "axs[1].plot(epochs, val_loss, 'y', label='Validation loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Value')\n",
    "axs[1].legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c38d8e-9855-4d74-b12f-16ebcd413550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "0359aab60893b2ae81cf58b65751dd49aacce33c63ff3968bf2555ef33ef870d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
